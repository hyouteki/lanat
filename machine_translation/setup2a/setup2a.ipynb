{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T15:39:45.019092Z","iopub.status.busy":"2024-04-02T15:39:45.018798Z","iopub.status.idle":"2024-04-02T15:39:50.510694Z","shell.execute_reply":"2024-04-02T15:39:50.509929Z","shell.execute_reply.started":"2024-04-02T15:39:45.019067Z"},"trusted":true},"outputs":[],"source":["from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from torchtext.datasets import multi30k, Multi30k\n","from typing import Iterable, List\n","import torch\n","from torchtext.data.utils import get_tokenizer\n","from datasets import load_dataset\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-02T15:39:50.512574Z","iopub.status.busy":"2024-04-02T15:39:50.512119Z","iopub.status.idle":"2024-04-02T15:39:50.516553Z","shell.execute_reply":"2024-04-02T15:39:50.515667Z","shell.execute_reply.started":"2024-04-02T15:39:50.512547Z"},"trusted":true},"outputs":[],"source":["SRC_LANGUAGE = \"de\"\n","TGT_LANGUAGE = \"en\""]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T15:39:50.518098Z","iopub.status.busy":"2024-04-02T15:39:50.517808Z","iopub.status.idle":"2024-04-02T15:39:50.531598Z","shell.execute_reply":"2024-04-02T15:39:50.530788Z","shell.execute_reply.started":"2024-04-02T15:39:50.518069Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","class WMT16Dataset(Dataset):\n","    def __init__(self, split):\n","        self.split = split\n","        self.data = load_dataset('wmt16', SRC_LANGUAGE + \"-\" + TGT_LANGUAGE, split=self.split)\n","    def __len__(self):\n","        return len(self.data)\n","    def __getitem__(self, index):\n","        srcText = self.data[index]['translation'][SRC_LANGUAGE]\n","        tgtText = self.data[index]['translation'][TGT_LANGUAGE]\n","        return srcText, tgtText"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T15:39:50.533809Z","iopub.status.busy":"2024-04-02T15:39:50.533545Z","iopub.status.idle":"2024-04-02T15:40:29.507688Z","shell.execute_reply":"2024-04-02T15:40:29.506205Z","shell.execute_reply.started":"2024-04-02T15:39:50.533786Z"},"trusted":true},"outputs":[],"source":["!python -m spacy download en_core_web_sm\n","!python -m spacy download de_core_news_sm"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T15:40:29.510443Z","iopub.status.busy":"2024-04-02T15:40:29.509499Z","iopub.status.idle":"2024-04-02T15:40:29.515609Z","shell.execute_reply":"2024-04-02T15:40:29.514377Z","shell.execute_reply.started":"2024-04-02T15:40:29.510398Z"},"trusted":true},"outputs":[],"source":["TRAIN_SPLIT_SIZE = 30000"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T15:40:29.517239Z","iopub.status.busy":"2024-04-02T15:40:29.516864Z","iopub.status.idle":"2024-04-02T15:45:04.653022Z","shell.execute_reply":"2024-04-02T15:45:04.651888Z","shell.execute_reply.started":"2024-04-02T15:40:29.517210Z"},"trusted":true},"outputs":[],"source":["token_transform = {}\n","vocab_transform = {}\n","token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n","token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n","def yield_tokens(dataIter: Iterable, language: str) -> List[str]:\n","    with tqdm(total=len(dataIter.data), desc=\"Evaluating\") as pbar:\n","        for dataSample in dataIter.data:\n","            yield token_transform[language](dataSample[\"translation\"][language])\n","            pbar.update(1)\n","UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n","special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n","for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","    train_iter = WMT16Dataset(split=f'train[:{TRAIN_SPLIT_SIZE}]')\n","    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n","                                                    min_freq=1,\n","                                                    specials=special_symbols,\n","                                                    special_first=True)\n","for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","    vocab_transform[ln].set_default_index(UNK_IDX)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T15:45:04.654695Z","iopub.status.busy":"2024-04-02T15:45:04.654273Z","iopub.status.idle":"2024-04-02T15:45:04.660278Z","shell.execute_reply":"2024-04-02T15:45:04.659282Z","shell.execute_reply.started":"2024-04-02T15:45:04.654667Z"},"trusted":true},"outputs":[],"source":["from torch import Tensor\n","import torch\n","import torch.nn as nn\n","from torch.nn import Transformer\n","import math\n","\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T15:45:04.661790Z","iopub.status.busy":"2024-04-02T15:45:04.661519Z","iopub.status.idle":"2024-04-02T15:45:04.683532Z","shell.execute_reply":"2024-04-02T15:45:04.682537Z","shell.execute_reply.started":"2024-04-02T15:45:04.661767Z"},"trusted":true},"outputs":[],"source":["# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n","class PositionalEncoding(nn.Module):\n","    def __init__(self,\n","                 emb_size: int,\n","                 dropout: float,\n","                 maxlen: int = 5000):\n","        super(PositionalEncoding, self).__init__()\n","        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n","        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n","        pos_embedding = torch.zeros((maxlen, emb_size))\n","        pos_embedding[:, 0::2] = torch.sin(pos * den)\n","        pos_embedding[:, 1::2] = torch.cos(pos * den)\n","        pos_embedding = pos_embedding.unsqueeze(-2)\n","        self.dropout = nn.Dropout(dropout)\n","        self.register_buffer('pos_embedding', pos_embedding)\n","    def forward(self, token_embedding: Tensor):\n","        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n","\n","# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, vocab_size: int, emb_size):\n","        super(TokenEmbedding, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_size)\n","        self.emb_size = emb_size\n","    def forward(self, tokens: Tensor):\n","        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n","\n","# Seq2Seq Network\n","class Seq2SeqTransformer(nn.Module):\n","    def __init__(self,\n","                 num_encoder_layers: int,\n","                 num_decoder_layers: int,\n","                 emb_size: int,\n","                 nhead: int,\n","                 src_vocab_size: int,\n","                 tgt_vocab_size: int,\n","                 dim_feedforward: int = 512,\n","                 dropout: float = 0.1):\n","        super(Seq2SeqTransformer, self).__init__()\n","        self.transformer = Transformer(d_model=emb_size,\n","                                       nhead=nhead,\n","                                       num_encoder_layers=num_encoder_layers,\n","                                       num_decoder_layers=num_decoder_layers,\n","                                       dim_feedforward=dim_feedforward,\n","                                       dropout=dropout)\n","        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n","        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n","        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n","        self.positional_encoding = PositionalEncoding(\n","            emb_size, dropout=dropout)\n","    def forward(self,\n","                src: Tensor,\n","                trg: Tensor,\n","                src_mask: Tensor,\n","                tgt_mask: Tensor,\n","                src_padding_mask: Tensor,\n","                tgt_padding_mask: Tensor,\n","                memory_key_padding_mask: Tensor):\n","        src_emb = self.positional_encoding(self.src_tok_emb(src))\n","        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n","        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n","                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n","        return self.generator(outs)\n","    def encode(self, src: Tensor, src_mask: Tensor):\n","        return self.transformer.encoder(self.positional_encoding(\n","                            self.src_tok_emb(src)), src_mask)\n","    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n","        return self.transformer.decoder(self.positional_encoding(\n","                          self.tgt_tok_emb(tgt)), memory,\n","                          tgt_mask)\n","\n","def generate_square_subsequent_mask(sz):\n","    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n","    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","    return mask\n","def create_mask(src, tgt):\n","    src_seq_len = src.shape[0]\n","    tgt_seq_len = tgt.shape[0]\n","    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n","    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n","    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n","    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n","    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T15:45:04.685006Z","iopub.status.busy":"2024-04-02T15:45:04.684741Z","iopub.status.idle":"2024-04-02T15:45:07.884210Z","shell.execute_reply":"2024-04-02T15:45:07.883426Z","shell.execute_reply.started":"2024-04-02T15:45:04.684983Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"]}],"source":["torch.manual_seed(0)\n","\n","SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n","TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n","EMB_SIZE = 512\n","NHEAD = 8\n","FFN_HID_DIM = 512\n","BATCH_SIZE = 32\n","NUM_ENCODER_LAYERS = 3\n","NUM_DECODER_LAYERS = 3\n","\n","transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n","                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n","\n","for p in transformer.parameters():\n","    if p.dim() > 1:\n","        nn.init.xavier_uniform_(p)\n","\n","transformer = transformer.to(DEVICE)\n","loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n","optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T15:45:07.889237Z","iopub.status.busy":"2024-04-02T15:45:07.888718Z","iopub.status.idle":"2024-04-02T15:45:07.897985Z","shell.execute_reply":"2024-04-02T15:45:07.897100Z","shell.execute_reply.started":"2024-04-02T15:45:07.889210Z"},"trusted":true},"outputs":[],"source":["from torch.nn.utils.rnn import pad_sequence\n","\n","# helper function to club together sequential operations\n","def sequential_transforms(*transforms):\n","    def func(txt_input):\n","        for transform in transforms:\n","            txt_input = transform(txt_input)\n","        return txt_input\n","    return func\n","\n","# function to add BOS/EOS and create tensor for input sequence indices\n","def tensor_transform(token_ids: List[int]):\n","    return torch.cat((torch.tensor([BOS_IDX]),\n","                      torch.tensor(token_ids),\n","                      torch.tensor([EOS_IDX])))\n","\n","# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n","text_transform = {}\n","for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n","                                               vocab_transform[ln], #Numericalization\n","                                               tensor_transform) # Add BOS/EOS and create tensor\n","\n","\n","# function to collate data samples into batch tensors\n","def collate_fn(batch):\n","    src_batch, tgt_batch = [], []\n","    for src_sample, tgt_sample in batch:\n","        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n","        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n","\n","    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n","    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n","    return src_batch, tgt_batch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T15:45:07.902362Z","iopub.status.busy":"2024-04-02T15:45:07.902054Z","iopub.status.idle":"2024-04-02T15:45:07.918796Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","def train_epoch(model, optimizer, trainDataLoader):\n","    model.train()\n","    losses = 0\n","    for src, tgt in trainDataLoader:\n","        src = src.to(DEVICE)\n","        tgt = tgt.to(DEVICE)\n","        tgt_input = tgt[:-1, :]\n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n","        optimizer.zero_grad()\n","        tgt_out = tgt[1:, :]\n","        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n","        loss.backward()\n","        optimizer.step()\n","        losses += loss.item()\n","    return losses/len(list(trainDataLoader))\n","\n","def evaluate_loss(model):\n","    model.eval()\n","    losses = 0\n","    val_iter = WMT16Dataset(split=\"validation\")\n","    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n","    for src, tgt in val_dataloader:\n","        src = src.to(DEVICE)\n","        tgt = tgt.to(DEVICE)\n","        tgt_input = tgt[:-1, :]\n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n","        tgt_out = tgt[1:, :]\n","        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n","        losses += loss.item()\n","    return losses / len(list(val_dataloader))"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T17:08:27.356719Z","iopub.status.busy":"2024-04-02T17:08:27.356049Z","iopub.status.idle":"2024-04-02T17:25:21.846453Z","shell.execute_reply":"2024-04-02T17:25:21.845492Z","shell.execute_reply.started":"2024-04-02T17:08:27.356689Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Training:   0%|          | 0/10 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1 Train loss: 2.936, Val loss: 5.063,  Epoch time = 16.236s\n","Epoch: 2 Train loss: 2.523, Val loss: 5.123,  Epoch time = 16.246s\n","Epoch: 3 Train loss: 2.260, Val loss: 5.136,  Epoch time = 16.270s\n","Epoch: 4 Train loss: 2.040, Val loss: 5.223,  Epoch time = 16.263s\n"]},{"name":"stderr","output_type":"stream","text":["Training:  10%|█         | 1/10 [01:42<15:20, 102.29s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5 Train loss: 1.844, Val loss: 5.428,  Epoch time = 16.236s\n","Epoch: 1 Train loss: 2.869, Val loss: 5.349,  Epoch time = 16.542s\n","Epoch: 2 Train loss: 2.455, Val loss: 5.463,  Epoch time = 16.481s\n","Epoch: 3 Train loss: 2.191, Val loss: 5.601,  Epoch time = 16.664s\n","Epoch: 4 Train loss: 1.975, Val loss: 5.723,  Epoch time = 16.644s\n"]},{"name":"stderr","output_type":"stream","text":["Training:  20%|██        | 2/10 [03:25<13:43, 102.88s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5 Train loss: 1.789, Val loss: 5.849,  Epoch time = 16.634s\n","Epoch: 1 Train loss: 2.805, Val loss: 5.496,  Epoch time = 16.110s\n","Epoch: 2 Train loss: 2.381, Val loss: 5.547,  Epoch time = 16.173s\n","Epoch: 3 Train loss: 2.114, Val loss: 5.718,  Epoch time = 16.125s\n","Epoch: 4 Train loss: 1.903, Val loss: 5.741,  Epoch time = 16.145s\n"]},{"name":"stderr","output_type":"stream","text":["Training:  30%|███       | 3/10 [05:07<11:57, 102.54s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5 Train loss: 1.718, Val loss: 5.860,  Epoch time = 16.213s\n","Epoch: 1 Train loss: 2.874, Val loss: 5.540,  Epoch time = 16.827s\n","Epoch: 2 Train loss: 2.433, Val loss: 5.588,  Epoch time = 16.840s\n","Epoch: 3 Train loss: 2.150, Val loss: 5.700,  Epoch time = 16.849s\n","Epoch: 4 Train loss: 1.931, Val loss: 5.789,  Epoch time = 16.839s\n"]},{"name":"stderr","output_type":"stream","text":["Training:  40%|████      | 4/10 [06:52<10:20, 103.43s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5 Train loss: 1.740, Val loss: 5.996,  Epoch time = 16.810s\n","Epoch: 1 Train loss: 2.727, Val loss: 5.384,  Epoch time = 16.064s\n","Epoch: 2 Train loss: 2.307, Val loss: 5.494,  Epoch time = 16.060s\n","Epoch: 3 Train loss: 2.035, Val loss: 5.584,  Epoch time = 16.039s\n","Epoch: 4 Train loss: 1.820, Val loss: 5.679,  Epoch time = 15.885s\n"]},{"name":"stderr","output_type":"stream","text":["Training:  50%|█████     | 5/10 [08:32<08:31, 102.26s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5 Train loss: 1.642, Val loss: 5.771,  Epoch time = 15.923s\n","Epoch: 1 Train loss: 2.702, Val loss: 5.179,  Epoch time = 16.395s\n","Epoch: 2 Train loss: 2.262, Val loss: 5.338,  Epoch time = 16.409s\n","Epoch: 3 Train loss: 1.985, Val loss: 5.451,  Epoch time = 16.473s\n","Epoch: 4 Train loss: 1.764, Val loss: 5.597,  Epoch time = 16.417s\n"]},{"name":"stderr","output_type":"stream","text":["Training:  60%|██████    | 6/10 [10:15<06:50, 102.58s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5 Train loss: 1.580, Val loss: 5.774,  Epoch time = 16.504s\n","Epoch: 1 Train loss: 2.673, Val loss: 4.594,  Epoch time = 16.085s\n","Epoch: 2 Train loss: 2.248, Val loss: 4.675,  Epoch time = 16.096s\n","Epoch: 3 Train loss: 1.984, Val loss: 4.786,  Epoch time = 16.211s\n","Epoch: 4 Train loss: 1.775, Val loss: 4.922,  Epoch time = 16.371s\n"]},{"name":"stderr","output_type":"stream","text":["Training:  70%|███████   | 7/10 [11:57<05:06, 102.18s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5 Train loss: 1.592, Val loss: 5.018,  Epoch time = 16.371s\n","Epoch: 1 Train loss: 2.650, Val loss: 4.581,  Epoch time = 15.717s\n","Epoch: 2 Train loss: 2.226, Val loss: 4.661,  Epoch time = 15.661s\n","Epoch: 3 Train loss: 1.956, Val loss: 4.805,  Epoch time = 15.651s\n","Epoch: 4 Train loss: 1.743, Val loss: 4.920,  Epoch time = 15.657s\n"]},{"name":"stderr","output_type":"stream","text":["Training:  80%|████████  | 8/10 [13:35<03:22, 101.02s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5 Train loss: 1.564, Val loss: 5.016,  Epoch time = 15.502s\n","Epoch: 1 Train loss: 2.567, Val loss: 4.584,  Epoch time = 15.673s\n","Epoch: 2 Train loss: 2.134, Val loss: 4.699,  Epoch time = 15.891s\n","Epoch: 3 Train loss: 1.868, Val loss: 4.797,  Epoch time = 15.869s\n","Epoch: 4 Train loss: 1.651, Val loss: 4.906,  Epoch time = 15.892s\n"]},{"name":"stderr","output_type":"stream","text":["Training:  90%|█████████ | 9/10 [15:15<01:40, 100.54s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5 Train loss: 1.483, Val loss: 5.040,  Epoch time = 15.852s\n","Epoch: 1 Train loss: 2.633, Val loss: 4.536,  Epoch time = 15.654s\n","Epoch: 2 Train loss: 2.199, Val loss: 4.634,  Epoch time = 15.653s\n","Epoch: 3 Train loss: 1.927, Val loss: 4.803,  Epoch time = 15.698s\n","Epoch: 4 Train loss: 1.714, Val loss: 4.905,  Epoch time = 15.654s\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 10/10 [16:54<00:00, 101.45s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5 Train loss: 1.537, Val loss: 5.021,  Epoch time = 15.692s\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["from timeit import default_timer as timer\n","NUM_CHUNKS = 10\n","CHUNK_SIZE = 5000\n","train_losses = []\n","val_losses = []\n","NUM_EPOCHS = 5\n","\n","with tqdm(total=NUM_CHUNKS, desc=\"Training\") as pbar:\n","    for i in range(NUM_CHUNKS):\n","        trainIter = WMT16Dataset(split=f\"train[{int(i*CHUNK_SIZE)}:{int((i+1)*CHUNK_SIZE)}]\")\n","        trainDataLoader = DataLoader(trainIter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n","        for epoch in range(1, NUM_EPOCHS+1):\n","            start_time = timer()\n","            train_loss = train_epoch(transformer, optimizer, trainDataLoader)\n","            end_time = timer()\n","            val_loss = evaluate_loss(transformer)\n","            train_losses.append(train_loss)\n","            val_losses.append(val_loss)\n","            print(f\"Epoch: {epoch} Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \",\n","                  f\"Epoch time = {(end_time - start_time):.3f}s\")\n","        pbar.update(1)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T17:32:12.544910Z","iopub.status.busy":"2024-04-02T17:32:12.544133Z","iopub.status.idle":"2024-04-02T17:32:14.632860Z","shell.execute_reply":"2024-04-02T17:32:14.631831Z","shell.execute_reply.started":"2024-04-02T17:32:12.544874Z"},"trusted":true},"outputs":[],"source":["torch.save(transformer, '/kaggle/working/transformer.pt')\n","torch.save(optimizer, '/kaggle/working/optimizer.pt')"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T17:33:32.675500Z","iopub.status.busy":"2024-04-02T17:33:32.675094Z","iopub.status.idle":"2024-04-02T17:33:32.681866Z","shell.execute_reply":"2024-04-02T17:33:32.680871Z","shell.execute_reply.started":"2024-04-02T17:33:32.675469Z"},"trusted":true},"outputs":[{"data":{"text/html":["<a href='transformer.pt' target='_blank'>transformer.pt</a><br>"],"text/plain":["/kaggle/working/transformer.pt"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["from IPython.display import FileLink\n","FileLink(r\"transformer.pt\")"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T17:40:00.301002Z","iopub.status.busy":"2024-04-02T17:40:00.300299Z","iopub.status.idle":"2024-04-02T17:40:00.307661Z","shell.execute_reply":"2024-04-02T17:40:00.306468Z","shell.execute_reply.started":"2024-04-02T17:40:00.300967Z"},"trusted":true},"outputs":[{"data":{"text/html":["<a href='optimizer.pt' target='_blank'>optimizer.pt</a><br>"],"text/plain":["/kaggle/working/optimizer.pt"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["FileLink(r\"optimizer.pt\")"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T17:34:34.460429Z","iopub.status.busy":"2024-04-02T17:34:34.460040Z","iopub.status.idle":"2024-04-02T17:34:34.465562Z","shell.execute_reply":"2024-04-02T17:34:34.464663Z","shell.execute_reply.started":"2024-04-02T17:34:34.460393Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[2.93555835098218, 2.5228596956107268, 2.260005887146968, 2.0395615283091355, 1.8436836323161034, 2.8686448783631535, 2.4549124058644485, 2.190834797112046, 1.9751192308535241, 1.7891666031187508, 2.8045938379445654, 2.3813386973302078, 2.1140699918103065, 1.9028279530774257, 1.7178909634328952, 2.8743009225578064, 2.4328575081126704, 2.150474805361146, 1.9308944374892363, 1.7402013593418584, 2.726984756008075, 2.306718485370563, 2.0353990535067905, 1.8195179761595028, 1.6423388916975374, 2.701938828085638, 2.2619586028870504, 1.9846835751442393, 1.763874110142896, 1.5800462896656837, 2.6733564609175273, 2.2482146776405867, 1.9840572085350183, 1.7747709781500944, 1.5923832203172574, 2.649979968739163, 2.226173712949085, 1.9562417686365212, 1.7434210879787517, 1.564313498272258, 2.5668379455615002, 2.1337405321704352, 1.8676150475338007, 1.6506046098508653, 1.48323946659732, 2.6328592642097717, 2.1990925096402503, 1.9273807121689912, 1.7138988125096462, 1.537241074309987]\n","[5.063400482430177, 5.123443242381601, 5.136434961767757, 5.223285117570092, 5.427771123016582, 5.349262945792255, 5.463323473930359, 5.600609768839443, 5.723019438631394, 5.848819788764505, 5.496493634055643, 5.546507263884825, 5.717899017474231, 5.7407240236506745, 5.859702432856841, 5.539556131643407, 5.588172807412989, 5.7003066750133735, 5.789422112352708, 5.995992022402146, 5.383917177424712, 5.493768250240999, 5.584255236036637, 5.678906531894908, 5.771212276290445, 5.179200582644519, 5.337619525544784, 5.450967501191532, 5.5970295772832985, 5.773795134880963, 4.594091247109806, 4.675141320509069, 4.7861169331214, 4.922263397889979, 5.018485998406129, 4.580965312088237, 4.661342981983633, 4.804890916627996, 4.920408560949213, 5.015736758708954, 4.583503758206087, 4.6992225331418656, 4.797484681886785, 4.906186549102559, 5.040003331268535, 4.536323922521928, 4.633716600782731, 4.802733375745661, 4.905433816068313, 5.020829660051009]\n"]}],"source":["print(train_losses)\n","print(val_losses)"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# function to generate output sequence using greedy algorithm\n","def greedy_decode(model, src, src_mask, max_len, start_symbol):\n","    src = src.to(DEVICE)\n","    src_mask = src_mask.to(DEVICE)\n","    memory = model.encode(src, src_mask)\n","    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n","    for i in range(max_len-1):\n","        memory = memory.to(DEVICE)\n","        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n","                    .type(torch.bool)).to(DEVICE)\n","        out = model.decode(ys, memory, tgt_mask)\n","        out = out.transpose(0, 1)\n","        prob = model.generator(out[:, -1])\n","        _, next_word = torch.max(prob, dim=1)\n","        next_word = next_word.item()\n","        ys = torch.cat([ys,\n","                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n","        if next_word == EOS_IDX:\n","            break\n","    return ys\n","\n","# actual function to translate input sentence into target language\n","def translate(model: torch.nn.Module, src_sentence: str):\n","    model.eval()\n","    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n","    num_tokens = src.shape[0]\n","    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n","    tgt_tokens = greedy_decode(\n","        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n","    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T17:34:37.534594Z","iopub.status.busy":"2024-04-02T17:34:37.534244Z","iopub.status.idle":"2024-04-02T17:35:14.191893Z","shell.execute_reply":"2024-04-02T17:35:14.190744Z","shell.execute_reply.started":"2024-04-02T17:34:37.534569Z"},"trusted":true},"outputs":[],"source":["!pip install evaluate\n","!pip install -U nltk\n","!pip install bert_score"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T17:35:27.172893Z","iopub.status.busy":"2024-04-02T17:35:27.172514Z","iopub.status.idle":"2024-04-02T17:35:27.177963Z","shell.execute_reply":"2024-04-02T17:35:27.176974Z","shell.execute_reply.started":"2024-04-02T17:35:27.172863Z"},"trusted":true},"outputs":[],"source":["import evaluate\n","from tqdm import tqdm\n","from pprint import pprint"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T17:35:30.367616Z","iopub.status.busy":"2024-04-02T17:35:30.367206Z","iopub.status.idle":"2024-04-02T17:39:08.732244Z","shell.execute_reply":"2024-04-02T17:39:08.731353Z","shell.execute_reply.started":"2024-04-02T17:35:30.367585Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 2169/2169 [03:36<00:00, 10.03it/s]\n"]}],"source":["translatedSamples, tgtSamples = [], []\n","dataIter = WMT16Dataset(split=\"validation\")\n","with tqdm(total=len(dataIter), desc=\"Evaluating\") as pbar:\n","    for dataSample in dataIter:\n","        translatedSamples.append(translate(transformer, dataSample[0]))\n","        tgtSamples.append(dataSample[1])\n","        pbar.update(1)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T17:40:11.239344Z","iopub.status.busy":"2024-04-02T17:40:11.238974Z","iopub.status.idle":"2024-04-02T17:40:21.184491Z","shell.execute_reply":"2024-04-02T17:40:21.183375Z","shell.execute_reply.started":"2024-04-02T17:40:11.239304Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","BLEU1\n","{'bleu': 0.26750774095790236, 'precisions': [0.26750774095790236], 'brevity_penalty': 1.0, 'length_ratio': 1.3073229550201322, 'translation_length': 60716, 'reference_length': 46443}\n","\n","BLEU2\n","{'bleu': 0.1368197636084783, 'precisions': [0.26750774095790236, 0.06997796642014108], 'brevity_penalty': 1.0, 'length_ratio': 1.3073229550201322, 'translation_length': 60716, 'reference_length': 46443}\n","\n","BLEU3\n","{'bleu': 0.07506759081825795, 'precisions': [0.26750774095790236, 0.06997796642014108, 0.02259746709709461], 'brevity_penalty': 1.0, 'length_ratio': 1.3073229550201322, 'translation_length': 60716, 'reference_length': 46443}\n","\n","BLEU4\n","{'bleu': 0.04331273866531156, 'precisions': [0.26750774095790236, 0.06997796642014108, 0.02259746709709461, 0.008319651718349351], 'brevity_penalty': 1.0, 'length_ratio': 1.3073229550201322, 'translation_length': 60716, 'reference_length': 46443}\n"]}],"source":["for maxOrder in range(1, 5):\n","    print(f\"\\nBLEU{maxOrder}\")\n","    print(evaluate.load(\"bleu\").compute(predictions=translatedSamples, references=tgtSamples, \n","                                        max_order=maxOrder))"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T17:40:25.625448Z","iopub.status.busy":"2024-04-02T17:40:25.624796Z","iopub.status.idle":"2024-04-02T17:40:32.886684Z","shell.execute_reply":"2024-04-02T17:40:32.885653Z","shell.execute_reply.started":"2024-04-02T17:40:25.625416Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["METEOR: {'meteor': 0.25484074117445193}\n"]}],"source":["print(f\"METEOR: {evaluate.load('meteor').compute(predictions=translatedSamples, references=tgtSamples)}\")"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T17:40:35.669891Z","iopub.status.busy":"2024-04-02T17:40:35.669540Z","iopub.status.idle":"2024-04-02T17:40:46.590748Z","shell.execute_reply":"2024-04-02T17:40:46.589788Z","shell.execute_reply.started":"2024-04-02T17:40:35.669864Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["BERT avg precision: 0.689967467687052\n","BERT avg recall: 0.7084532111622102\n","BERT avg f1: 0.6987526666573963\n"]}],"source":["bertScores = evaluate.load(\"bertscore\").compute(predictions=translatedSamples,\n","                                                references=tgtSamples, lang=\"de\")\n","bertPrecisions = bertScores['precision']\n","bertRecalls = bertScores['recall']\n","bertF1s = bertScores['f1']\n","print(f\"BERT avg precision: {(sum(bertPrecisions)/len(bertPrecisions))}\")\n","print(f\"BERT avg recall: {(sum(bertRecalls)/len(bertRecalls))}\")\n","print(f\"BERT avg f1: {(sum(bertF1s)/len(bertF1s))}\")"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T17:41:10.715003Z","iopub.status.busy":"2024-04-02T17:41:10.714169Z","iopub.status.idle":"2024-04-02T17:46:17.520531Z","shell.execute_reply":"2024-04-02T17:46:17.519460Z","shell.execute_reply.started":"2024-04-02T17:41:10.714972Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 2999/2999 [05:04<00:00,  9.84it/s]\n"]}],"source":["translatedSamples, tgtSamples = [], []\n","dataIter = WMT16Dataset(split=\"test\")\n","with tqdm(total=len(dataIter), desc=\"Evaluating\") as pbar:\n","    for dataSample in dataIter:\n","        translatedSamples.append(translate(transformer, dataSample[0]))\n","        tgtSamples.append(dataSample[1])\n","        pbar.update(1)"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T17:46:24.804931Z","iopub.status.busy":"2024-04-02T17:46:24.804576Z","iopub.status.idle":"2024-04-02T17:46:35.094106Z","shell.execute_reply":"2024-04-02T17:46:35.093194Z","shell.execute_reply.started":"2024-04-02T17:46:24.804903Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","BLEU1\n","{'bleu': 0.26845394966998626, 'precisions': [0.26845394966998626], 'brevity_penalty': 1.0, 'length_ratio': 1.3374194856438808, 'translation_length': 85754, 'reference_length': 64119}\n","\n","BLEU2\n","{'bleu': 0.14011584077381548, 'precisions': [0.26845394966998626, 0.07313153283789499], 'brevity_penalty': 1.0, 'length_ratio': 1.3374194856438808, 'translation_length': 85754, 'reference_length': 64119}\n","\n","BLEU3\n","{'bleu': 0.07892169272467453, 'precisions': [0.26845394966998626, 0.07313153283789499, 0.025038868549074677], 'brevity_penalty': 1.0, 'length_ratio': 1.3374194856438808, 'translation_length': 85754, 'reference_length': 64119}\n","\n","BLEU4\n","{'bleu': 0.046641883104234394, 'precisions': [0.26845394966998626, 0.07313153283789499, 0.025038868549074677, 0.009627535533292512], 'brevity_penalty': 1.0, 'length_ratio': 1.3374194856438808, 'translation_length': 85754, 'reference_length': 64119}\n"]}],"source":["for maxOrder in range(1, 5):\n","    print(f\"\\nBLEU{maxOrder}\")\n","    print(evaluate.load(\"bleu\").compute(predictions=translatedSamples, references=tgtSamples, \n","                                        max_order=maxOrder))"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T17:46:37.302871Z","iopub.status.busy":"2024-04-02T17:46:37.302082Z","iopub.status.idle":"2024-04-02T17:46:45.280640Z","shell.execute_reply":"2024-04-02T17:46:45.279755Z","shell.execute_reply.started":"2024-04-02T17:46:37.302843Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["METEOR: {'meteor': 0.26291187738117555}\n"]}],"source":["print(f\"METEOR: {evaluate.load('meteor').compute(predictions=translatedSamples, references=tgtSamples)}\")"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T17:46:50.650535Z","iopub.status.busy":"2024-04-02T17:46:50.649700Z","iopub.status.idle":"2024-04-02T17:47:05.245545Z","shell.execute_reply":"2024-04-02T17:47:05.244486Z","shell.execute_reply.started":"2024-04-02T17:46:50.650505Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["BERT avg precision: 0.6901324533867653\n","BERT avg recall: 0.7094622124390191\n","BERT avg f1: 0.6993435171891467\n"]}],"source":["bertScores = evaluate.load(\"bertscore\").compute(predictions=translatedSamples,\n","                                                references=tgtSamples, lang=\"de\")\n","bertPrecisions = bertScores['precision']\n","bertRecalls = bertScores['recall']\n","bertF1s = bertScores['f1']\n","print(f\"BERT avg precision: {(sum(bertPrecisions)/len(bertPrecisions))}\")\n","print(f\"BERT avg recall: {(sum(bertRecalls)/len(bertRecalls))}\")\n","print(f\"BERT avg f1: {(sum(bertF1s)/len(bertF1s))}\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
