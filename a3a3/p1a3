import torch
from torch import nn
import torch.nn.functional as F
from transformers import BertTokenizer, BertModel
from torch.utils.data import Dataset, DataLoader
import pandas as pd


class SimilarityDataset(Dataset):
    def __init__(self, data, tokenizer, max_len):
        self.data = data
        self.tokenizer = tokenizer
        self.max_len = max_len

    def __len__(self):
        return len(self.data)

    def __getitem__(self, index):
        row = self.data.iloc[index]

        # Check if any of the required columns are missing
        if 'score' not in row or pd.isna(row['score']):
            score = 0.0
        else:
            score = float(row['score'])  # Convert score to float

        if 'sentence1' not in row or pd.isna(row['sentence1']):
            sentence1 = ''
        else:
            sentence1 = row['sentence1']

        if 'sentence2' not in row or pd.isna(row['sentence2']):
            sentence2 = ''
        else:
            sentence2 = row['sentence2']

        inputs = self.tokenizer.encode_plus(
            sentence1,
            sentence2,
            add_special_tokens=True,
            max_length=self.max_len,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )

        input_ids = inputs['input_ids'].squeeze()
        token_type_ids = inputs['token_type_ids'].squeeze()
        attention_mask = inputs['attention_mask'].squeeze()

        return input_ids, token_type_ids, attention_mask, torch.tensor(score, dtype=torch.double)


train_data = pd.read_csv('train.csv', sep='\t', names=['score', 'sentence1', 'sentence2'])
val_data = pd.read_csv('dev.csv', sep='\t', names=['score', 'sentence1', 'sentence2'])

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
max_len = 128

train_dataset = SimilarityDataset(train_data, tokenizer, max_len)
val_dataset = SimilarityDataset(val_data, tokenizer, max_len)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16)

class SimilarityModel(nn.Module):
    def __init__(self):
        super(SimilarityModel, self).__init__()
        self.bert = BertModel.from_pretrained('bert-base-uncased')
        self.bert.to(torch.double)  # Convert BERT model to double precision
        self.dropout = nn.Dropout(0.1)
        self.fc = nn.Linear(768, 1, dtype=torch.double)  # Create linear layer with double precision

    def forward(self, input_ids, token_type_ids, attention_mask):
        outputs = self.bert(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)
        pooled_output = outputs.pooler_output
        dropout_output = self.dropout(pooled_output)
        logits = self.fc(dropout_output)
        return logits.squeeze(-1)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = SimilarityModel().to(device)
criterion = nn.MSELoss(reduction='mean')
optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)

epochs = 3

for epoch in range(epochs):
    model.train()
    total_loss = 0
    for input_ids, token_type_ids, attention_mask, scores in train_loader:
        print("calculating")
        input_ids = input_ids.to(device)
        token_type_ids = token_type_ids.to(device)
        attention_mask = attention_mask.to(device)
        scores = scores.to(device)

        optimizer.zero_grad()
        outputs = model(input_ids, token_type_ids, attention_mask)
        loss = criterion(outputs, scores)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}')

    # Evaluation on validation set
    model.eval()
    total_val_loss = 0
    with torch.no_grad():
        for input_ids, token_type_ids, attention_mask, scores in val_loader:
            input_ids = input_ids.to(device)
            token_type_ids = token_type_ids.to(device)
            attention_mask = attention_mask.to(device)
            scores = scores.to(device)

            outputs = model(input_ids, token_type_ids, attention_mask)
            loss = criterion(outputs, scores)
            total_val_loss += loss.item()

    print(f'Validation Loss: {total_val_loss / len(val_loader)}')
